#!/Users/xupeng/miniconda3/bin/python

import os
import sys
import argparse
from dataclasses import dataclass
from typing import Any

projectRoot = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, projectRoot)

from milkie.runtime.engine import Engine
from milkie.server.openai_server import OpenAIServer

@dataclass
class Args:
    agent: str
    chatroom: str
    config: str
    file: str
    folder: str
    query: str
    server: bool
    port: int

def parseArgs() -> Args:
    parser = argparse.ArgumentParser()
    parser.add_argument('--agent', type=str, help='agent name')
    parser.add_argument('--chatroom', type=str, help='chatroom name')
    parser.add_argument('--config', type=str, help='config file path')
    parser.add_argument('--file', type=str, help='program file path')
    parser.add_argument('--folder', type=str, help='program folder path')
    parser.add_argument('--query', type=str, help='query')
    parser.add_argument('--server', action='store_true', help='run as OpenAI compatible server')
    parser.add_argument('--port', type=int, default=8000, help='server port')
    args = parser.parse_args()
    return Args(**vars(args))

def main():
    args = parseArgs()
    
    # 创建 engine
    engine = Engine(
        folder=args.folder,
        file=args.file,
        config=args.config
    )
    
    # 如果是服务器模式
    if args.server:
        if not args.agent:
            print("Error: --agent is required when running in server mode")
            sys.exit(1)
        
        server = OpenAIServer(engine=engine, agent_name=args.agent)
        server.run(port=args.port)
        return
    
    # 普通模式
    if args.query:
        queryArgs = {"query": args.query}
    else:
        queryArgs = {}
        
    engine.run(
        chatroom=args.chatroom,
        agent=args.agent,
        args=queryArgs
    )

if __name__ == '__main__':
    main()