llm:
  type: GEN_OPENAI
  model: deepseek-chat
  system_prompt: system_qwen
  framework : VLLM
  device: CUDA
  port: 10230
  deployment_name: "gpt-35-turbo-16k"
  api_key: "41157f060dc04dea8dd063b8716ec721"
  endpoint: "https://api.deepseek.com"
  api_version: "2023-12-01-preview"
  ctx_len: 8192
  batch_size: 4
  model_args:
    torch_compile: False
    quantization_type: NONE
    attn_implementation: flash_attention_2
  generation_args:
    repetition_penalty: 1.0
    temperature: 0
    top_k: 1
    top_p: 0.9
    do_sample: False
    use_cache: True
    prompt_lookup_num_tokens: 20
llm_code:
  type: GEN_OPENAI 
  model: deepseek-coder
  system_prompt: system_qwen
  api_key: "sk-d6061da0d2d64e78a8061a2de*"
  endpoint: "https://api.deepseek.com"
  api_version: "2023-12-01-preview"
  ctx_len: 8192
memory:
  - type: LONG_TERM
    source: LOCAL
    path: ./data/santi/
index:
  chunk_size: 256
  chunk_overlap: 50
embedding:
  type: HUGGINGFACE
  model: /Users/xupeng/.cache/huggingface/hub/models--BAAI--bge-large-zh-v1.5/snapshots/c11661ba3f9407eeb473765838eb4437e0f015c0/
  device: CUDA
agents:
  - config: qa
    type: QA
    retrieval:
      rewrite_strategy: HYDE
      channel_recall: 30
      similarity_top_k: 20
      reranker:
        name: FLAGEMBED # FLAGEMBED | NONE
        model: /mnt/data1/.cache/huggingface/hub/models--BAAI--bge-reranker-large/
        position: SIMPLE
  - config: query_rewrite
    type: PROMPT
