llm:
  type: HUGGINGFACE
  model: /mnt/data1/.cache/huggingface/hub/01ai/Yi-34B-Chat/
  system_prompt: system_qwen
  framework : VLLM
  device: CUDA
  port: 10230
  deployment_name: "gpt-35-turbo-16k"
  api_key: "41157f060dc04dea8dd063b8716ec721"
  azure_endpoint: "https://artificial-intelligence-01.openai.azure.com/"
  api_version: "2023-12-01-preview"
  ctx_len: 8192
  batch_size: 4
  model_args:
    torch_compile: False
    quantization_type: NONE
    attn_implementation: flash_attention_2
  generation_args:
    repetition_penalty: 1.0
    temperature: 0
    top_k: 1
    top_p: 0.9
    do_sample: False
    use_cache: True
    prompt_lookup_num_tokens: 20
memory:
  - type: LONG_TERM
    source: LOCAL
    path: ./data/santi/
index:
  chunk_size: 256
  chunk_overlap: 50
embedding:
  type: HUGGINGFACE
  model: /mnt/data1/.cache/huggingface/hub/models--BAAI--bge-large-zh-v1.5/
  device: CUDA
agents:
  - config: qa
    type: QA
    retrieval:
      rewrite_strategy: HYDE
      channel_recall: 30
      similarity_top_k: 20
      reranker:
        name: FLAGEMBED # FLAGEMBED | NONE
        model: /mnt/data1/.cache/huggingface/hub/models--BAAI--bge-reranker-large/
        position: SIMPLE
  - config: retrieval
    type: QA
    retrieval:
      rewrite_strategy: HYDE
      channel_recall: 30
      similarity_top_k: 20
      reranker:
        name: FLAGEMBED # FLAGEMBED | NONE
        model: /mnt/data1/.cache/huggingface/hub/models--BAAI--bge-reranker-large/
        position: SIMPLE
  - config: query_rewrite
    type: PROMPT