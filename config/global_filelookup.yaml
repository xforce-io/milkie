llm:
  type: GEN_OPENAI
  model: yi-large
  system_prompt: system_qwen
  framework : VLLM
  device: CUDA
  port: 10230
  deployment_name: "gpt-35-turbo-16k"
  api_key: "88051c5c05f5487ba8*"
  endpoint: "https://api.lingyiwanwu.com/v1"
  api_version: "2023-12-01-preview"
  ctx_len: 8192
  batch_size: 4
  model_args:
    torch_compile: False
    quantization_type: NONE
    attn_implementation: flash_attention_2
  generation_args:
    repetition_penalty: 1.0
    temperature: 0
    top_k: 1
    top_p: 0.9
    do_sample: False
    use_cache: True
    prompt_lookup_num_tokens: 20
llm_code:
  type: GEN_OPENAI 
  model: deepseek-coder
  system_prompt: system_qwen
  api_key: "sk-d6061da0d2d6*"
  endpoint: "https://api.deepseek.com"
  api_version: "2023-12-01-preview"
  ctx_len: 8192
memory:
  - type: LONG_TERM
    source: LOCAL
    path: ./data/file_lookup/
index:
  chunk_size: 256
  chunk_overlap: 50
agents:
  - config: file_lookup
    type: QA
    retrieval:
      rewrite_strategy: HYDE
      channel_recall: 30
      similarity_top_k: 20
      reranker:
        name: FLAGEMBED # FLAGEMBED | NONE
        model: /mnt/data1/.cache/huggingface/hub/models--BAAI--bge-reranker-large/
        position: SIMPLE
  - config: query_rewrite
    type: PROMPT
